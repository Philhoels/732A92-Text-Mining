{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# L3: Text clustering and topic modelling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Text clustering groups documents** in such a way that documents within a group are **more &lsquo;similar&rsquo; to other documents in the cluster** than to documents not in the cluster. The exact definition of what &lsquo;similar&rsquo; means in this context varies across applications and clustering algorithms.\n",
    "\n",
    "In this lab you will **experiment with** both **hard and soft clustering** techniques. More specifically, in the first part you will be using the **$k$-means** algorithm, and in the second part you will be using a topic model based on the **Latent Dirichlet Allocation (LDA)**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [],
   "source": [
    "# a list of all imports\n",
    "import pandas as pd\n",
    "import bz2\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.cluster import KMeans\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hard clustering data set"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The **raw data** for the **hard clustering** part of this lab is a collection of **product reviews**. We have **preprocessed** the **data by tokenization and lowercasing**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import bz2\n",
    "\n",
    "with bz2.open(\"reviews.json.bz2\") as source:\n",
    "    df = pd.read_json(source)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When you inspect the data frame, you can see that there are **three labelled columns**: `category` (the product category), `sentiment` (whether the product review was classified as &lsquo;positive&rsquo; or &lsquo;negative&rsquo; towards the product), and `text` (the space-separated text of the review)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>category</th>\n",
       "      <th>sentiment</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>music</td>\n",
       "      <td>neg</td>\n",
       "      <td>i bought this album because i loved the title ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>music</td>\n",
       "      <td>neg</td>\n",
       "      <td>i was misled and thought i was buying the enti...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>books</td>\n",
       "      <td>neg</td>\n",
       "      <td>i have introduced many of my ell , high school...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>books</td>\n",
       "      <td>pos</td>\n",
       "      <td>anything you purchase in the left behind serie...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>dvd</td>\n",
       "      <td>pos</td>\n",
       "      <td>i loved these movies , and i cant wiat for the...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  category sentiment                                               text\n",
       "0    music       neg  i bought this album because i loved the title ...\n",
       "1    music       neg  i was misled and thought i was buying the enti...\n",
       "2    books       neg  i have introduced many of my ell , high school...\n",
       "3    books       pos  anything you purchase in the left behind serie...\n",
       "4      dvd       pos  i loved these movies , and i cant wiat for the..."
      ]
     },
     "execution_count": 163,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['books' 'camera' 'dvd' 'health' 'music' 'software']\n",
      "Length: 6\n"
     ]
    }
   ],
   "source": [
    "# check categories\n",
    "print(np.unique(df.category))\n",
    "print(\"Length: {}\".format(len(np.unique(df.category))))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problem 1: K-means clustering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Your first task is to** cluster** the **product review** data **using** a **tfâ€“idf vectorizer** and a **$k$-means clusterer**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Start by doing the vectorization. In connection with vectorization, you should also **filter out** standard **English stop words**. While you could use [spaCy](https://spacy.io/) for this task, here it suffices to use the word list implemented in [TfidfVectorizer](https://scikit-learn.org/stable/modules/generated/sklearn.feature_extraction.text.TfidfVectorizer.html)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "# init vectorizer\n",
    "vectorizer = TfidfVectorizer(stop_words='english')\n",
    "reviews = vectorizer.fit_transform(df.text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Test your vectorization by running the following code cell:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(11914, 46619)"
      ]
     },
     "execution_count": 166,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reviews.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you used the **English stop** word list from scikit-learn, then the resulting vocabulary should have 46,619 entries."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, **cluster the vectorized data**. Before doing so, you should **read** the **documentation** of the [KMeans](https://scikit-learn.org/stable/modules/generated/sklearn.cluster.KMeans.html) class, which is scikit-learn&rsquo;s implementation of the $k$-means algorithm. As you can see, this **class has several parameters that you can tweak**. For now, the only parameter that you will have to **set** is the **number of clusters**. We **recommend** that you choose $k=3$.\n",
    "\n",
    "**Tip:** Training $k$-means models will take some time. To **speed things up**, you can use the **`n_init` parameter** to control the **number of times** that the clustering is **re-computed** with different initial values. The **default** value for this parameter is **10**; here and in the rest of this lab, you may want to **set** this to a **lower** value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "KMeans(algorithm='auto', copy_x=True, init='k-means++', max_iter=300,\n",
       "    n_clusters=3, n_init=3, n_jobs=1, precompute_distances='auto',\n",
       "    random_state=13, tol=0.0001, verbose=0)"
      ]
     },
     "execution_count": 167,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.cluster import KMeans\n",
    "# init kmean object\n",
    "k_cluster = 3\n",
    "\n",
    "# random_state - so my group partner and I can compare\n",
    "kmeans_p1 = KMeans(n_clusters=k_cluster, n_init=3,  random_state=13) \n",
    "kmeans_p1.fit(reviews)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To **sanity-check** your clustering, **create** a **bar plot** with the number of documents per cluster."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 0 0 ... 2 2 2]\n",
      "<class 'numpy.ndarray'>\n"
     ]
    }
   ],
   "source": [
    "# check labels\n",
    "print(kmeans_p1.labels_)\n",
    "print(type(kmeans_p1.labels_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    6031\n",
       "2    4805\n",
       "1    1078\n",
       "dtype: int64"
      ]
     },
     "execution_count": 171,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# convert array to series, so we can use value_counts()\n",
    "cluster_count = pd.Series(kmeans_p1.labels_) \n",
    "cluster_count = cluster_count.value_counts()\n",
    "\n",
    "# check the count of the clusters\n",
    "cluster_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1a1ec3d6d8>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "cluster_count.plot(kind=\"bar\")\n",
    "plt.xlabel(\"Cluster\")\n",
    "plt.ylabel(\"Counts\")\n",
    "plt.title(\"KMeans cluster counts\", y=1.02)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that sizes may vary considerable between clusters and among different random seeds."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problem 2: Summarize clusters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once you have a clustering, you can try to see whether it is meaningful. One **useful technique** in that context is to generate a **summary** for **each cluster** by **extracting** the **$n$ highest-weighted terms** from the centroid of each cluster. Your next task is to implement this approach.\n",
    "\n",
    "**Hint:** You will need to **construct** an **&lsquo;inverted vocabulary&rsquo;** that allows you to map from the index of a term back to the original term."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Testing start\n",
    "#### This part is just testing\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save kmeans object for this specific exercise\n",
    "# \n",
    "kmeans_p2 = kmeans_p1\n",
    "cluster_centers = kmeans_p2.cluster_centers_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[3.05042594e-04 5.28391140e-04 0.00000000e+00 ... 4.45502443e-05\n",
      "  3.44213882e-05 2.35197077e-05]\n",
      " [2.07289830e-03 9.97789218e-04 0.00000000e+00 ... 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00]\n",
      " [1.42649530e-03 8.37028586e-04 5.37167764e-05 ... 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00]]\n",
      "ncol: 3\n",
      "nrow: 46619\n"
     ]
    }
   ],
   "source": [
    "# check Coordinates of cluster centers\n",
    "print(cluster_centers)\n",
    "\n",
    "# we have to find the index of the max k values of each array\n",
    "\n",
    "# check dimension of the nested array\n",
    "print(\"ncol: {}\".format(len(cluster_centers)))\n",
    "ncol = len(cluster_centers)\n",
    "print(\"nrow: {}\".format(len(cluster_centers[0])))\n",
    "nrow = len(cluster_centers[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#vectorizer.vocabulary_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['000', '0003', '000mb', '004144', '007', '00am', '00pm', '01', '02']"
      ]
     },
     "execution_count": 175,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check the first 10 feature names\n",
    "vectorizer.get_feature_names()[1:10]\n",
    "\n",
    "# the indexes of the k highest values do we have to plug in to feature names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "46619\n",
      "[3.05042594e-04 5.28391140e-04 0.00000000e+00 ... 4.45502443e-05\n",
      " 3.44213882e-05 2.35197077e-05]\n"
     ]
    }
   ],
   "source": [
    "# check the first array of the nested array\n",
    "print(len(kmeans_p2.cluster_centers_[0]))\n",
    "# each array has a length of 46619\n",
    "print(kmeans_p2.cluster_centers_[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create above in loop\n",
    "k = 6\n",
    "# save highest weighted terms in dict\n",
    "hwt = {}\n",
    "n_cluster = range(ncol)\n",
    "for i in n_cluster:\n",
    "    hwt[i] = np.argpartition(cluster_centers[i], -k)[-k:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: array([22961,  7423,  2193, 27522, 24390,  5695]),\n",
       " 1: array([44007, 12123,  6980, 31125, 24143,  6890]),\n",
       " 2: array([44011, 32568, 38539, 12823, 44007, 32505])}"
      ]
     },
     "execution_count": 241,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hwt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 261,
   "metadata": {},
   "outputs": [],
   "source": [
    "# access the get_feature_names and plug in the indexes from above\n",
    "\n",
    "test_dic = {}\n",
    "test_list = []\n",
    "for i in range(ncol):\n",
    "    test_list = []\n",
    "    for j in range(k):\n",
    "        test_list.append(vectorizer.get_feature_names()[hwt[i][j]])\n",
    "    test_dic[i] = test_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 262,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: ['just', 'cd', 'album', 'movie', 'like', 'book'],\n",
       " 1: ['use', 'digital', 'canon', 'pictures', 'lens', 'camera'],\n",
       " 2: ['used', 'program', 'software', 'does', 'use', 'product']}"
      ]
     },
     "execution_count": 262,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_dic"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Testing end\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 266,
   "metadata": {},
   "outputs": [],
   "source": [
    "def summary(k_cluster, N_summary_words):\n",
    "    \"fits k-means with reviews and prints a summary of each cluster\"\n",
    "    \n",
    "    # create k-means object und fit\n",
    "    # random_state - so my group partner and I can compare\n",
    "    kmeans = KMeans(n_clusters=k_cluster, n_init=3,  random_state=13).fit(reviews)\n",
    "    \n",
    "    cluster_centers = kmeans.cluster_centers_\n",
    "    # save dimensions of the nested array\n",
    "    ncol = len(cluster_centers)\n",
    "    nrow = len(cluster_centers[0])\n",
    "    \n",
    "    ### save highest weighted terms in dict\n",
    "    \n",
    "    # in this part I save the N_summary_words INDEX with the hihgest values of each array\n",
    "    hwt_index = {}\n",
    "    n_cluster = range(ncol)\n",
    "    for i in n_cluster:\n",
    "        hwt_index[i] = np.argpartition(cluster_centers[i], -N_summary_words)[-N_summary_words:]\n",
    "    \n",
    "    # in this part I save the N_summary_words WRODS with the hihgest values of each array\n",
    "    hwt_word = {}\n",
    "    for i in range(ncol):\n",
    "        saveinlist = []\n",
    "        for j in range(k):\n",
    "            saveinlist.append(vectorizer.get_feature_names()[hwt_index[i][j]])\n",
    "        hwt_word[i] = saveinlist\n",
    "    \n",
    "    for i in range(k_cluster):\n",
    "        print(\"Summary of cluster {}:{}\".format(i,hwt_word[i]))\n",
    "    \n",
    "    #return hwt_word"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once you have computed the cluster summaries, **discuss** their **quality**. Is it **clear** what the reviews in a given cluster are about? Which clusters are **clearest**? Which are **less clear**? Do the cluster summaries contain any unexpected terms? What happens if you **re-cluster** with, say, $k=6$?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['books' 'camera' 'dvd' 'health' 'music' 'software']\n",
      "Length: 6\n"
     ]
    }
   ],
   "source": [
    "# check categories of the review again\n",
    "print(np.unique(df.category))\n",
    "print(\"Length: {}\".format(len(np.unique(df.category))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 267,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Summary of cluster 0:['just', 'cd', 'album', 'movie', 'like', 'book']\n",
      "Summary of cluster 1:['use', 'digital', 'canon', 'pictures', 'lens', 'camera']\n",
      "Summary of cluster 2:['used', 'program', 'software', 'does', 'use', 'product']\n"
     ]
    }
   ],
   "source": [
    "# Case: 3 cluster, with 6 summary words\n",
    "summary(3,6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 268,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Summary of cluster 0:['song', 'quot', 'songs', 'music', 'cd', 'album']\n",
      "Summary of cluster 1:['use', 'digital', 'canon', 'pictures', 'camera', 'lens']\n",
      "Summary of cluster 2:['computer', 'use', 'product', 'version', 'program', 'software']\n",
      "Summary of cluster 3:['just', 'like', 'use', 'good', 'product', 'great']\n",
      "Summary of cluster 4:['story', 'reading', 'books', 'author', 'read', 'book']\n",
      "Summary of cluster 5:['watch', 'story', 'like', 'movies', 'movie', 'film']\n"
     ]
    }
   ],
   "source": [
    "# Case: 6 cluster, with 6 summary words\n",
    "summary(6,6)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** Interpretation **\n",
    "\n",
    "- General observations\n",
    "\n",
    "We created the vectorizer with english stop words. However, there are still few meaningful words in all clusters (eg. use, used) that could be fixed with better data preparation via lemma and pos (no verbs). \n",
    "\n",
    "- Case: 3 cluster\n",
    "\n",
    "The overall quality is \"Neutral\" to express it in the vernacular of Sentiment Analysis.\n",
    "All clusters have their weaknesses. Some make the combinations of words are, however, there are also words that are inappropriate.\n",
    "For example, in cluster 0 \"cd\" and \"album\" together makes sense, but in combination with \"cd\", \"album\" and \"movie\" makes less sense. These are two different categories (music, movie). \n",
    "The words fit best in cluster 1, worst in cluster 0. Cluster 2 makes sense in itself, but 3 of 6 words are not very meaningful.\n",
    "\n",
    "- Case: 6 cluster\n",
    "\n",
    "The number of clusters makes sense because we know from previous studies that all descriptions are divided into 6 categories. Therefore, we can also see that the classification is much better than with 3 clusters. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problem 3: Tune the k-means algorithm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A **major limitation** of the **$k$-means** algorithm is that one has to **manually set** the value for $k$, the number of clusters. One **heuristic** that can help you with this is the [Elbow method](https://en.wikipedia.org/wiki/Elbow_method_(clustering)). Your next task is to implement this method to see whether it allows you to find a better value for $k$.\n",
    "\n",
    "To follow the elbow method, you should **plot different** values of $k$ against the **inertia** (sums of squared distances between documents and closest centroids) of the fitted $k$-means model, and pick the $k$ at the &lsquo;elbow point&rsquo; of the resulting graph. Test cluster sizes between 1 and 9.\n",
    "\n",
    "**Note that this will take a while.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loop over grid (range(1,9)) and save inertia_ of each object \n",
    "# check how long the cell run\n",
    "\n",
    "inertia = []\n",
    "for i in range(1,10):\n",
    "    kmeans = KMeans(n_clusters=i, n_init=3,  random_state=13) # to get same results with my group partner\n",
    "    kmeans.fit(reviews)\n",
    "    inertia.append(kmeans.inertia_) \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    11764.202586\n",
      "1    11696.561592\n",
      "2    11655.909417\n",
      "3    11616.535698\n",
      "4    11584.609693\n",
      "5    11552.705787\n",
      "6    11532.566770\n",
      "7    11496.550916\n",
      "8    11479.845398\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "inertia = pd.Series(inertia)\n",
    "print(inertia)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1a14f50128>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(range(1,10),inertia, linestyle='-', marker='o', color='b')\n",
    "plt.xlabel(\"Cluster size\")\n",
    "plt.ylabel(\"inertia\")\n",
    "plt.title(\"sums of squared distances between documents and closest centroids for each cluster\", y=1.02)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once you have the diagram, can you see a pronounced &lsquo;elbow point&rsquo;? Discuss your findings in a short text."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** Interpretation **\n",
    "\n",
    "The elbow method is a tool to find a suitable number of clusters when clustering kmeans. However, it is hard to tell from this plot what the ideal number of clusters is. It looks like sums of squared distances are reduced at similar intervals. However, it can be seen that cluster 7's reduction is less than in the steps before.\n",
    "This information and the information from the previous task, I would set 6 as the number of clusters.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problem 4: Compare clusterings using the Rand index"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In some scenarios, you may have **gold-standard class labels available** for at least a subset of your documents. In these cases you can compute the **Rand index** of a clustering, and use this **measure to compare the quality of different clusterings**.\n",
    "\n",
    "To **compute** the **Rand index**, we view a clustering as a binary classifier on pairs of documents. The **classifier predicts** **&lsquo;positive&rsquo;** *if and only if* the **two documents belong to the same cluster**. The (non-normalized) Rand index of the clustering is the accuracy of this classifier relative to a reference in which a document pair belongs to the &lsquo;positive&rsquo; class if and only if the two documents in the pair have the same gold-standard class label.\n",
    "\n",
    "Compare a **clustering with** $k=3$ clusters to a **second clustering** with $k=6$ clusters. As your **evaluation data**, use the **first 500 documents** from the original data set along with their **gold-standard categories** (from the `category` column). What do you **observe**? How do you **interpret** your observations? What **arguments** can you find **against** the **Rand index** as a measure for comparing clusterings?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Enter code here to compute the Rand indices for the two clusterings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 276,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create the evaluate data\n",
    "evaluation = df[0:500]\n",
    "evaluation_text = df[0:500]\n",
    "evaluation_text = evaluation_text.text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 271,
   "metadata": {},
   "outputs": [],
   "source": [
    "# case k = 3\n",
    "# init kmean object\n",
    "k_cluster = 3\n",
    "\n",
    "# random_state - so my group partner and I can compare\n",
    "kmeans_p4k3 = KMeans(n_clusters=k_cluster, n_init=3,  random_state=13).fit(reviews)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 278,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "could not convert string to float: \"i bought this album because i loved the title song . it 's such a great song , how bad can the rest of the album be , right ? well , the rest of the songs are just filler and are n't worth the money i paid for this . it 's either shameless bubblegum or oversentimentalized depressing tripe . kenny chesney is a popular artist and as a result he is in the cookie cutter category of the nashville music scene . he 's gotta pump out the albums so the record company can keep lining their pockets while the suckers out there keep buying this garbage to perpetuate more garbage coming out of that town . i 'll get down off my soapbox now . but country music really needs to get back to it 's roots and stop this pop nonsense . what country music really is and what it is considered to be by mainstream are two different things .\"",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-278-993cb9ea0041>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mkmeans_p4k3\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mevaluation_text\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/anaconda3/lib/python3.6/site-packages/sklearn/cluster/k_means_.py\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m    986\u001b[0m         \u001b[0mcheck_is_fitted\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'cluster_centers_'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    987\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 988\u001b[0;31m         \u001b[0mX\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_check_test_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    989\u001b[0m         \u001b[0mx_squared_norms\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrow_norms\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msquared\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    990\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0m_labels_inertia\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx_squared_norms\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcluster_centers_\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.6/site-packages/sklearn/cluster/k_means_.py\u001b[0m in \u001b[0;36m_check_test_data\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m    863\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    864\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_check_test_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 865\u001b[0;31m         \u001b[0mX\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcheck_array\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maccept_sparse\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'csr'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mFLOAT_DTYPES\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    866\u001b[0m         \u001b[0mn_samples\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_features\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    867\u001b[0m         \u001b[0mexpected_n_features\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcluster_centers_\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.6/site-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36mcheck_array\u001b[0;34m(array, accept_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, warn_on_dtype, estimator)\u001b[0m\n\u001b[1;32m    431\u001b[0m                                       force_all_finite)\n\u001b[1;32m    432\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 433\u001b[0;31m         \u001b[0marray\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0morder\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0morder\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    434\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    435\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mensure_2d\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.6/site-packages/pandas/core/series.py\u001b[0m in \u001b[0;36m__array__\u001b[0;34m(self, dtype)\u001b[0m\n\u001b[1;32m    726\u001b[0m             \u001b[0mwarnings\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwarn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmsg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mFutureWarning\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstacklevel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    727\u001b[0m             \u001b[0mdtype\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'M8[ns]'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 728\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    729\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    730\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__array_wrap__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcontext\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/numpy/core/_asarray.py\u001b[0m in \u001b[0;36masarray\u001b[0;34m(a, dtype, order)\u001b[0m\n\u001b[1;32m     83\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     84\u001b[0m     \"\"\"\n\u001b[0;32m---> 85\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0morder\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0morder\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     86\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     87\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.6/site-packages/pandas/core/arrays/numpy_.py\u001b[0m in \u001b[0;36m__array__\u001b[0;34m(self, dtype)\u001b[0m\n\u001b[1;32m    169\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    170\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__array__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 171\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_ndarray\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    172\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    173\u001b[0m     \u001b[0m_HANDLED_TYPES\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndarray\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnumbers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mNumber\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/numpy/core/_asarray.py\u001b[0m in \u001b[0;36masarray\u001b[0;34m(a, dtype, order)\u001b[0m\n\u001b[1;32m     83\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     84\u001b[0m     \"\"\"\n\u001b[0;32m---> 85\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0morder\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0morder\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     86\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     87\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: could not convert string to float: \"i bought this album because i loved the title song . it 's such a great song , how bad can the rest of the album be , right ? well , the rest of the songs are just filler and are n't worth the money i paid for this . it 's either shameless bubblegum or oversentimentalized depressing tripe . kenny chesney is a popular artist and as a result he is in the cookie cutter category of the nashville music scene . he 's gotta pump out the albums so the record company can keep lining their pockets while the suckers out there keep buying this garbage to perpetuate more garbage coming out of that town . i 'll get down off my soapbox now . but country music really needs to get back to it 's roots and stop this pop nonsense . what country music really is and what it is considered to be by mainstream are two different things .\""
     ]
    }
   ],
   "source": [
    "kmeans_p4k3.predict(evaluation_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# case k = 6\n",
    "# init kmean object\n",
    "k_cluster = 6\n",
    "\n",
    "# random_state - so my group partner and I can compare\n",
    "kmeans_p4k6 = KMeans(n_clusters=k_cluster, n_init=3,  random_state=13).fit_predictre(reviews)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Interpretation**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The edge index with the cluster number of 6 shows a better result than the edge index with 3 clusters. \n",
    "However, the difference is very small! \n",
    "These results were to be expected due to the evaluation of the previous tasks (problem 2 & 3). \n",
    "Also that the results could hardly differ can already be seen in the evaluation of the elbow method. The differences of sums of squared distances were very small (about 250 of 1-10 cluster problem 3)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Topic modelling data set"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The **data set for the topic modelling part** of this lab is the collection of all [State of the Union](https://en.wikipedia.org/wiki/State_of_the_Union) addresses from the years 1975â€“2000. These speeches come as a single text file with one sentence per line. The following code cell prints the first 5 lines from the data file:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 279,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mr speaker mr vice president members of the 94th congress and distinguished guests\n",
      "twenty six years ago a freshman congressman a young fellow with lots of idealism who was out to change the world stood before sam rayburn in the well of the house and solemnly swore to the same oath that all of you took yesterday an unforgettable experience and i congratulate you all\n",
      "two days later that same freshman stood at the back of this great chamber over there someplace as president truman all charged up by his single handed election victory reported as the constitution requires on the state of the union\n",
      "when the bipartisan applause stopped president truman said i am happy to report to this 81st congress that the state of the union is good our nation is better able than ever before to meet the needs of the american people and to give them their fair chance in the pursuit of happiness it is foremost among the nations of the world in the search for peace\n",
      "today that freshman member from michigan stands where mr truman stood and i must say to you that the state of the union is not good\n",
      "millions of americans are out of work\n"
     ]
    }
   ],
   "source": [
    "with open(\"sotu_1975_2000.txt\") as source:\n",
    "    for i, line in enumerate(source):\n",
    "        print(line.rstrip())\n",
    "        if i >= 5:\n",
    "            break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problem 5: Train a topic model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Your first task on the topic modelling data is to **train** an **LDA model**. For this task you will be using [spaCy](https://spacy.io/) and the [gensim](https://radimrehurek.com/gensim/) topic modelling library.\n",
    "\n",
    "Start by **preprocessing** the **data using spaCy**. Given that the data set for this problem is rather small, you do not have to exclude any components from the standard pipeline. **Filter out stop words, non-alphabetic tokens, and tokens less than 3 characters in length**. **Store** the **documents** as a **nested list** where the first level of nesting corresponds to the sentences and the second level corresponds to the tokens in each sentence."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Replace the following lines with your own code for preprocessing the documents\n",
    "with open(\"sotu_1975_2000.txt\") as source:\n",
    "    documents = [line.split() for line in source]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Test your preprocessing by running the following cell:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\" \".join(documents[42])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You should get the following output:"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "'reduce oil imports million barrels day end year million barrels day end'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once you have the list of documents, skim the section [Pre-process and vectorize the documents](https://radimrehurek.com/gensim/auto_examples/tutorials/run_lda.html#pre-process-and-vectorize-the-documents) of the gensim documentation to learn how to create the dictionary and the vectorized corpus representation required by gensim. (Note that you cannot use the standard scikit-learn pipeline in this case.) Then, write code to train an [LdaModel](https://radimrehurek.com/gensim/models/ldamodel.html) for $k=10$ topics, and using default values for all other parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Enter code here to train an LDA model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once you have a trained model, run the following cell to print the topics:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.print_topics()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Inspect the topics. Do they make sense? Can you &lsquo;label&rsquo; each topic with a short description of what it is about? Do the topics contain any unexpected terms? Summarize your discussion in a short text."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** Interpretation **"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " I would categorize the first 5 topics as follows. \n",
    "\n",
    " - Social, human, health \n",
    " - human, youth\n",
    " - military, \n",
    " - upcoming challanges\n",
    " - economic, market\n",
    " - school system and changes (7)\n",
    " \n",
    "In the first 5 categories a Topic is to be recognized relatively fast and clearly. \n",
    "After that, however, it becomes more difficult. \n",
    "This may be due to the fact that the words are not so easy to classify. \n",
    "Or that the topics are very specific and not so rough. In this case, however, you would have to invest a little more time in classification to find the right topics. \n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problem 6: Monitoring a topic model for convergence"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When learning an LDA model, it is important to make sure that the training algorithm has converged to a stable posterior distribution. One way to do so is to plot, after each training epochs(or &lsquo;pass&rsquo;, in gensim parlance) the log likelihood of the training data under the posterior. Your last task in this lab is to create such a plot and, based on this, to suggest an appropriate number of epochs.\n",
    "\n",
    "To collect information about the posterior likelihood after each pass, we need to enable the logging facilities of gensim. Once this is done, gensim will add various diagnostics to a log file `gensim.log`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "\n",
    "logging.basicConfig(filename=\"gensim.log\", format=\"%(asctime)s:%(levelname)s:%(message)s\", level=logging.INFO)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following function will parse the generated logfile and return the list of log likelihoods."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "def parse_logfile():\n",
    "    matcher = re.compile(\"(-*\\d+\\.\\d+) per-word .* (\\d+\\.\\d+) perplexity\")\n",
    "    likelihoods = []\n",
    "    with open(\"gensim.log\") as source:\n",
    "        for line in source:\n",
    "            match = matcher.search(line)\n",
    "            if match:\n",
    "                likelihoods.append(float(match.group(1)))\n",
    "    return likelihoods"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Your task now is to re-train your LDA model for 50&nbsp;passes, retrieve the list of log likelihoods, and create a plot from this data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Enter code here to generate the convergence plot"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How do you interpret your plot? What would be a reasonable choice for the number of passes? Retrain your LDA model with that number and re-inspect the topics it finds. Do you consider the new topics to be &lsquo;better&rsquo; than the ones that you got from the 1-pass model in Problem&nbsp;5?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** Interpretation **"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Case passes = 50\n",
    "\n",
    "In the plot we can see that the value of the log-likelihood convolves after about 5-7 iterations.  \n",
    "Accordingly, we take 10 for the next run of the LDAs and investigate changes.\n",
    "\n",
    "- Case passes = 10"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-info\">\n",
    "    Please read the section â€˜General informationâ€™ on the â€˜Labsâ€™ page of the course website before submitting this notebook!\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### helpful links:\n",
    "\n",
    "- vectorization\n",
    "\n",
    "https://scikit-learn.org/stable/modules/generated/sklearn.feature_extraction.text.TfidfVectorizer.html\n",
    "\n",
    "https://python-graph-gallery.com/cheat-sheets/\n",
    "    \n",
    "\n",
    "- k-mean\n",
    "\n",
    "https://scikit-learn.org/stable/modules/generated/sklearn.cluster.KMeans.html\n",
    "\n",
    "- plot\n",
    "\n",
    "https://dfrieds.com/data-visualizations/bar-plot-python-pandas\n",
    "\n",
    "- max value index\n",
    "\n",
    "https://stackoverflow.com/questions/16817948/i-have-need-the-n-minimum-index-values-in-a-numpy-array\n",
    "\n",
    "- dict\n",
    "\n",
    "https://stackoverflow.com/questions/30280856/populating-a-dictionary-using-for-loops-python\n",
    "https://stackoverflow.com/questions/5404665/accessing-elements-of-python-dictionary-by-index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
